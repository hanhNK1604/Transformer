{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "095362f4",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-03T05:11:28.416839Z",
     "iopub.status.busy": "2024-05-03T05:11:28.416470Z",
     "iopub.status.idle": "2024-05-03T05:11:32.921257Z",
     "shell.execute_reply": "2024-05-03T05:11:32.920230Z"
    },
    "papermill": {
     "duration": 4.517169,
     "end_time": "2024-05-03T05:11:32.923825",
     "exception": false,
     "start_time": "2024-05-03T05:11:28.406656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import json\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fc8c27b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T05:11:32.940632Z",
     "iopub.status.busy": "2024-05-03T05:11:32.940218Z",
     "iopub.status.idle": "2024-05-03T05:11:32.946408Z",
     "shell.execute_reply": "2024-05-03T05:11:32.945525Z"
    },
    "papermill": {
     "duration": 0.01657,
     "end_time": "2024-05-03T05:11:32.948437",
     "exception": false,
     "start_time": "2024-05-03T05:11:32.931867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Embedder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model=512):\n",
    "        super(Embedder, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = d_model\n",
    "\n",
    "        self.embed = nn.Embedding(vocab_size, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.embed(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0406a789",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T05:11:32.964397Z",
     "iopub.status.busy": "2024-05-03T05:11:32.963745Z",
     "iopub.status.idle": "2024-05-03T05:11:32.972505Z",
     "shell.execute_reply": "2024-05-03T05:11:32.971607Z"
    },
    "papermill": {
     "duration": 0.018884,
     "end_time": "2024-05-03T05:11:32.974491",
     "exception": false,
     "start_time": "2024-05-03T05:11:32.955607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PositionalEncoder(nn.Module):\n",
    "    def __init__(self, seq_len, d_model):\n",
    "        super(PositionalEncoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        pe = torch.zeros(seq_len, self.d_model)\n",
    "        for pos in range(seq_len):\n",
    "            for i in range(0, self.d_model, 2):\n",
    "                pe[pos, i] = math.sin(pos / (10000 ** ((2 * i)/self.d_model)))\n",
    "                pe[pos, i + 1] = math.cos(pos / (10000 ** ((2 * (i + 1))/self.d_model)))\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x * math.sqrt(self.d_model)\n",
    "        seq_len = x.size(1)\n",
    "        x = x + torch.autograd.Variable(self.pe[:, :seq_len], requires_grad=False)\n",
    "        return x\n",
    "\n",
    "\n",
    "# test\n",
    "# a = torch.rand(size=(32, 10, 512))\n",
    "# net = PositionalEncoder(seq_len=10, d_model=512)\n",
    "# b = net(a)\n",
    "# b.requires_grad\n",
    "# b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3df1a902",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T05:11:32.989779Z",
     "iopub.status.busy": "2024-05-03T05:11:32.989510Z",
     "iopub.status.idle": "2024-05-03T05:11:33.008218Z",
     "shell.execute_reply": "2024-05-03T05:11:33.007264Z"
    },
    "papermill": {
     "duration": 0.029184,
     "end_time": "2024-05-03T05:11:33.010788",
     "exception": false,
     "start_time": "2024-05-03T05:11:32.981604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiheadAttention(nn.Module):\n",
    "  def __init__(self, d_model=512, n_head=8):\n",
    "    super(MultiheadAttention, self).__init__()\n",
    "    self.d_model = d_model\n",
    "    self.n_head = n_head\n",
    "    self.d_k = int(d_model/n_head)\n",
    "\n",
    "    self.q_matrix = nn.Linear(d_model, d_model)\n",
    "    self.k_matrix = nn.Linear(d_model, d_model)\n",
    "    self.v_matrix = nn.Linear(d_model, d_model)\n",
    "    self.o_matrix = nn.Linear(d_model, d_model)\n",
    "\n",
    "  def split_head(self, x):\n",
    "    # x: (32, 10, 512)\n",
    "    batch_size = x.shape[0]\n",
    "    return x.view(batch_size, -1, self.n_head, self.d_k).permute(0, 2, 1, 3) #(32, 10, 512) => (32, 10, 8, 64) => (32, 8, 10, 64)\n",
    "\n",
    "  def forward(self, q, k, v, mask = None):\n",
    "    \"\"\"\n",
    "    q, k, v: (batch_size, seq_len, d_model)\n",
    "    mask\n",
    "    \"\"\"\n",
    "\n",
    "    batch_size = q.shape[0]\n",
    "\n",
    "    q = self.q_matrix(q)\n",
    "    k = self.k_matrix(k)\n",
    "    v = self.v_matrix(v)\n",
    "\n",
    "    q, k, v = self.split_head(q), self.split_head(k), self.split_head(v) #(32, 8, 10, 64)\n",
    "    k = k.transpose(-2, -1) #(32, 8, 64, 10)\n",
    "\n",
    "    score = torch.matmul(q, k)/math.sqrt(self.d_model) #(32, 8, 10, 10)\n",
    "    if mask is not None:\n",
    "      score = score.masked_fill(mask == 0, -1e9)\n",
    "    score = nn.functional.softmax(score, dim=-1)\n",
    "\n",
    "    attn_score = torch.matmul(score, v) #(32, 8, 10, 64)\n",
    "    attn_score = attn_score.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n",
    "\n",
    "    output = self.o_matrix(attn_score)\n",
    "    return output\n",
    "\n",
    "# x = torch.rand(size=(32, 10, 512))\n",
    "# net = MultiheadAttention(d_model=512, n_head=8)\n",
    "# a = net(k=x, q=x, v=x)\n",
    "# a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "541955e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T05:11:33.030751Z",
     "iopub.status.busy": "2024-05-03T05:11:33.029913Z",
     "iopub.status.idle": "2024-05-03T05:11:33.227767Z",
     "shell.execute_reply": "2024-05-03T05:11:33.226418Z"
    },
    "papermill": {
     "duration": 0.210548,
     "end_time": "2024-05-03T05:11:33.230231",
     "exception": false,
     "start_time": "2024-05-03T05:11:33.019683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 10, 512])\n"
     ]
    }
   ],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "  def __init__(self, d_model=512, n_head=8, factor=4):\n",
    "    super(TransformerBlock, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.n_head = n_head\n",
    "    self.factor = factor\n",
    "\n",
    "    self.multihead_attention = MultiheadAttention(d_model, n_head)\n",
    "    self.norm1 = nn.LayerNorm(d_model)\n",
    "    self.norm2 = nn.LayerNorm(d_model)\n",
    "\n",
    "    self.feed_forward = nn.Sequential(\n",
    "        nn.Linear(d_model, factor*d_model),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(factor*d_model, d_model)\n",
    "    )\n",
    "\n",
    "    self.dropout1 = nn.Dropout(0.2)\n",
    "    self.dropout2 = nn.Dropout(0.2)\n",
    "\n",
    "  def forward(self, q, k, v):\n",
    "    \"\"\"\n",
    "    x: (batch_size, sequence length, embedded dimension)\n",
    "    \"\"\"\n",
    "\n",
    "    attention_out = self.multihead_attention(q, k, v)\n",
    "    attention_res_out = attention_out + v\n",
    "    norm1_out = self.dropout1(self.norm1(attention_res_out))\n",
    "    fw_out = self.feed_forward(norm1_out)\n",
    "    fw_res_out = norm1_out + fw_out\n",
    "    norm2_out = self.dropout2(self.norm2(fw_res_out))\n",
    "\n",
    "    return norm2_out\n",
    "\n",
    "\n",
    "\n",
    "x = torch.rand(size=(32, 10, 512))\n",
    "net = TransformerBlock(d_model=512, n_head=8)\n",
    "a = net(x, x, x)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5836b06f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T05:11:33.248427Z",
     "iopub.status.busy": "2024-05-03T05:11:33.247606Z",
     "iopub.status.idle": "2024-05-03T05:11:33.374099Z",
     "shell.execute_reply": "2024-05-03T05:11:33.373049Z"
    },
    "papermill": {
     "duration": 0.137437,
     "end_time": "2024-05-03T05:11:33.376422",
     "exception": false,
     "start_time": "2024-05-03T05:11:33.238985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 10, 512])\n"
     ]
    }
   ],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, seq_len, vocab_size, d_model=512, num_layer=6, factor=4, n_head=8):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.vocab_size = vocab_size\n",
    "        self.num_layer = num_layer\n",
    "        self.factor = factor\n",
    "        self.n_head = n_head\n",
    "        self.d_model = d_model\n",
    "\n",
    "        self.embedding_layer = Embedder(vocab_size=vocab_size, d_model=d_model)\n",
    "        self.positional_encoder = PositionalEncoder(seq_len=seq_len, d_model=d_model)\n",
    "\n",
    "        self.layers = nn.ModuleList([TransformerBlock(d_model=d_model, n_head=n_head, factor=factor) for i in range(num_layer)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        embed_out = self.embedding_layer(x)\n",
    "        out = self.positional_encoder(embed_out)\n",
    "        for layer in self.layers:\n",
    "            out = layer(out, out, out)\n",
    "\n",
    "        return out\n",
    "\n",
    "x = torch.randint(size=(32, 10), low=1, high=100)\n",
    "net = TransformerEncoder(seq_len=10, vocab_size=200, num_layer=1)\n",
    "a = net(x)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea176ab3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T05:11:33.393567Z",
     "iopub.status.busy": "2024-05-03T05:11:33.393227Z",
     "iopub.status.idle": "2024-05-03T05:11:33.401154Z",
     "shell.execute_reply": "2024-05-03T05:11:33.400227Z"
    },
    "papermill": {
     "duration": 0.019157,
     "end_time": "2024-05-03T05:11:33.403424",
     "exception": false,
     "start_time": "2024-05-03T05:11:33.384267",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "  def __init__(self, d_model=512, factor=4, n_head=8):\n",
    "    super(DecoderBlock, self).__init__()\n",
    "    self.d_model = d_model\n",
    "    self.factor = factor\n",
    "    self.n_head = n_head\n",
    "\n",
    "    self.attention = MultiheadAttention(d_model, n_head=8)\n",
    "    self.norm = nn.LayerNorm(d_model)\n",
    "    self.dropout = nn.Dropout(0.2)\n",
    "    self.transformer_block = TransformerBlock(d_model, factor=factor, n_head=n_head)\n",
    "\n",
    "  def forward(self, x, k, v, mask):\n",
    "    attention = self.attention(x, x, x, mask=mask)\n",
    "    q = self.dropout(self.norm(attention + x))\n",
    "    out = self.transformer_block(q, k, v)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8553e68b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T05:11:33.421732Z",
     "iopub.status.busy": "2024-05-03T05:11:33.420770Z",
     "iopub.status.idle": "2024-05-03T05:11:33.431669Z",
     "shell.execute_reply": "2024-05-03T05:11:33.430577Z"
    },
    "papermill": {
     "duration": 0.022621,
     "end_time": "2024-05-03T05:11:33.433947",
     "exception": false,
     "start_time": "2024-05-03T05:11:33.411326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerDecoder(nn.Module):\n",
    "  def __init__(self, seq_len, vocab_size, d_model = 512, num_layer=2, factor=4, n_head=8):\n",
    "    super(TransformerDecoder, self).__init__()\n",
    "    self.vocab_size = vocab_size\n",
    "    self.d_model = d_model\n",
    "    self.num_layer = num_layer\n",
    "    self.factor = factor\n",
    "    self.n_head = n_head\n",
    "\n",
    "    self.embedding_layer = Embedder(vocab_size=vocab_size, d_model=d_model)\n",
    "    self.positional_encoder = PositionalEncoder(seq_len=seq_len, d_model=d_model)\n",
    "\n",
    "    self.layers = nn.ModuleList([\n",
    "        DecoderBlock(d_model, factor=factor, n_head=n_head)\n",
    "        for i in range(self.num_layer)\n",
    "    ])\n",
    "\n",
    "    self.fc_out = nn.Linear(d_model, vocab_size)\n",
    "    self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "  def forward(self, x, encoder_out, mask):\n",
    "    x = self.embedding_layer(x)\n",
    "    x = self.positional_encoder(x)\n",
    "    x = self.dropout(x)\n",
    "\n",
    "    for layer in self.layers:\n",
    "      x = layer(x=x, k=encoder_out, v=encoder_out, mask=mask)\n",
    "\n",
    "    out = nn.functional.softmax(self.fc_out(x), dim=-1) #batch_size, seq_len, vocab_size\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "520c4d57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T05:11:33.451605Z",
     "iopub.status.busy": "2024-05-03T05:11:33.450935Z",
     "iopub.status.idle": "2024-05-03T05:11:33.463724Z",
     "shell.execute_reply": "2024-05-03T05:11:33.462826Z"
    },
    "papermill": {
     "duration": 0.02413,
     "end_time": "2024-05-03T05:11:33.465946",
     "exception": false,
     "start_time": "2024-05-03T05:11:33.441816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "  def __init__(self, d_model, src_vocab_size, target_vocab_size, seq_len, num_layer=6, factor=4, n_head=8):\n",
    "    super(Transformer, self).__init__()\n",
    "    self.d_model = d_model\n",
    "    self.src_vocab_size = src_vocab_size\n",
    "    self.target_vocab_size = target_vocab_size\n",
    "    self.seq_len = seq_len\n",
    "    self.num_laye = num_layer\n",
    "    self.factor = factor\n",
    "    self.n_head = n_head\n",
    "\n",
    "    self.encoder = TransformerEncoder(seq_len=seq_len, vocab_size=src_vocab_size, d_model=d_model, num_layer=num_layer, factor=factor, n_head=n_head)\n",
    "    self.decoder = TransformerDecoder(seq_len=seq_len, vocab_size=target_vocab_size, d_model=d_model, num_layer=num_layer, factor=factor, n_head=n_head)\n",
    "\n",
    "  def make_target_mask(self, trg):\n",
    "    device = trg.device\n",
    "    tgt_mask = (trg != 0).unsqueeze(1).unsqueeze(3).to(device)\n",
    "    seq_length = trg.size(1)\n",
    "    nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool().to(device)\n",
    "    tgt_mask = tgt_mask & nopeak_mask\n",
    "    return tgt_mask.to(trg.device)\n",
    "\n",
    "  def decode(self, src):\n",
    "\n",
    "\n",
    "        batch_size, seq_len = src.shape[0], src.shape[1]\n",
    "        trg = torch.zeros(size=(batch_size, seq_len), dtype=torch.int)\n",
    "        trg[:, 0] = 1\n",
    "\n",
    "        enc_out = self.encoder(src)\n",
    "\n",
    "        for i in range(1, seq_len):\n",
    "          trg_mask = self.make_target_mask(trg)\n",
    "          out = self.decoder(x=trg, encoder_out=enc_out, mask=trg_mask)\n",
    "          out = out.argmax(-1)[:, i]\n",
    "          trg[:, i] = out\n",
    "\n",
    "        return trg\n",
    "\n",
    "  def forward(self, src, trg):\n",
    "\n",
    "    trg_mask = self.make_target_mask(trg)\n",
    "    enc_out = self.encoder(src)\n",
    "\n",
    "    outputs = self.decoder(trg, enc_out, trg_mask)\n",
    "    return outputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24a9c73f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T05:11:33.482482Z",
     "iopub.status.busy": "2024-05-03T05:11:33.481615Z",
     "iopub.status.idle": "2024-05-03T05:11:33.486866Z",
     "shell.execute_reply": "2024-05-03T05:11:33.486021Z"
    },
    "papermill": {
     "duration": 0.015077,
     "end_time": "2024-05-03T05:11:33.488719",
     "exception": false,
     "start_time": "2024-05-03T05:11:33.473642",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "en = []\n",
    "vi = []\n",
    "en_path = \"/kaggle/input/transformer/en_sents.txt\"\n",
    "vi_path = \"/kaggle/input/transformer/vi_sents.txt\"\n",
    "\n",
    "num_word_vi_path = \"/kaggle/input/transformer/num_word_vi.json\"\n",
    "word_num_vi_path = \"/kaggle/input/transformer/word_num_vi.json\"\n",
    "num_word_en_path = \"/kaggle/input/transformer/num_word_en.json\"\n",
    "word_num_en_path = \"/kaggle/input/transformer/word_num_en.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc1e1f62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T05:11:33.503317Z",
     "iopub.status.busy": "2024-05-03T05:11:33.503040Z",
     "iopub.status.idle": "2024-05-03T05:11:33.629847Z",
     "shell.execute_reply": "2024-05-03T05:11:33.628883Z"
    },
    "papermill": {
     "duration": 0.136471,
     "end_time": "2024-05-03T05:11:33.632066",
     "exception": false,
     "start_time": "2024-05-03T05:11:33.495595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_json(path):\n",
    "  with open(path) as f:\n",
    "    d = json.load(f)\n",
    "\n",
    "  return d\n",
    "\n",
    "def get_dict(lang: str):\n",
    "  if lang == \"vi\":\n",
    "    num_word_vi_path = \"/kaggle/input/transformer/num_word_vi.json\"\n",
    "    word_num_vi_path = \"/kaggle/input/transformer/word_num_vi.json\"\n",
    "\n",
    "    num_word, word_num = read_json(num_word_vi_path), read_json(word_num_vi_path)\n",
    "    return word_num, num_word\n",
    "\n",
    "  if lang == \"en\":\n",
    "    num_word_en_path = \"/kaggle/input/transformer/num_word_en.json\"\n",
    "    word_num_en_path = \"/kaggle/input/transformer/word_num_en.json\"\n",
    "    num_word, word_num = read_json(num_word_en_path), read_json(word_num_en_path)\n",
    "    return word_num, num_word\n",
    "\n",
    "\n",
    "word_num_en, num_word_en = get_dict(lang=\"en\")\n",
    "word_num_vi, num_word_vi = get_dict(lang=\"vi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82629ee3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T05:11:33.648481Z",
     "iopub.status.busy": "2024-05-03T05:11:33.648159Z",
     "iopub.status.idle": "2024-05-03T05:11:33.660276Z",
     "shell.execute_reply": "2024-05-03T05:11:33.659380Z"
    },
    "papermill": {
     "duration": 0.022257,
     "end_time": "2024-05-03T05:11:33.662457",
     "exception": false,
     "start_time": "2024-05-03T05:11:33.640200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tôi yêu em nhưng tôi ngu'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_sentence(sentence):\n",
    "  sentence = re.sub(\n",
    "  r\"[\\*\\\"“”\\n\\\\…\\+\\-\\/\\=\\(\\)‘•:\\[\\]\\|’\\!;]\", \" \", str(sentence))\n",
    "  sentence = re.sub(r',', '', sentence)\n",
    "  sentence = re.sub(r\"[ ]+\", \" \", sentence)\n",
    "  sentence = re.sub(r\"\\!+\", \"!\", sentence)\n",
    "  sentence = re.sub(r\"\\,+\", \",\", sentence)\n",
    "  sentence = re.sub(r\"\\?+\", \"?\", sentence)\n",
    "  sentence = re.sub(r\"\\.$\", \"\", sentence)\n",
    "  sentence = re.sub(r\"\\!$\", \"\", sentence)\n",
    "  sentence = re.sub(r\"\\?$\", \"\", sentence)\n",
    "  sentence = sentence.lower()\n",
    "\n",
    "  return sentence\n",
    "\n",
    "sentence=\"tôi yêu em, nhưng tôi ngu\"\n",
    "process_sentence(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecf761c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T05:11:33.679852Z",
     "iopub.status.busy": "2024-05-03T05:11:33.679285Z",
     "iopub.status.idle": "2024-05-03T05:11:34.117114Z",
     "shell.execute_reply": "2024-05-03T05:11:34.116053Z"
    },
    "papermill": {
     "duration": 0.448919,
     "end_time": "2024-05-03T05:11:34.119285",
     "exception": false,
     "start_time": "2024-05-03T05:11:33.670366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['xin vui lòng đặt người quét rác trong tủ chổi', 'im lặng một lát', 'đọc này', 'tom thuyết phục người quản lý cửa hàng trả lại tiền cho anh ta.', 'tình bạn bao gồm sự hiểu biết lẫn nhau', 'ngày mai bạn có đến không', 'nhìn thấy vấn đề này ngay lập tức, bạn sẽ?', 'tôi đã cho bạn bè của tôi xem những tấm bưu thiếp hình ảnh.', 'mary là em út trong ba chị em', 'anh ấy có hai người dì ở bên mẹ.']\n",
      "tensor([  1,  43, 284,  34,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0])\n"
     ]
    }
   ],
   "source": [
    "def text_to_tensor(sentence, lang, seq_len = 64):\n",
    "  word_num = None\n",
    "  num_word = None\n",
    "  if lang == \"en\": \n",
    "    word_num, num_word = word_num_en, num_word_en\n",
    "  elif lang == \"vi\": \n",
    "    word_num, num_word = word_num_vi, num_word_vi\n",
    "  \n",
    "  sentence = process_sentence(sentence)\n",
    "  sentence = sentence.split()\n",
    "  sentence = ['<START>'] + sentence + [\"<EOS>\"]\n",
    "  if len(sentence) < seq_len:\n",
    "    spare_len = seq_len - len(sentence)\n",
    "    sentence = sentence + [\"<PAD>\"] * spare_len\n",
    "\n",
    "  for i in range(len(sentence)):\n",
    "    if sentence[i] not in word_num:\n",
    "      sentence[i] = word_num['<UNK>']\n",
    "    sentence[i] = word_num[sentence[i]]\n",
    "\n",
    "  sentence = torch.tensor(sentence)\n",
    "\n",
    "  return sentence\n",
    "\n",
    "def read_data(path):\n",
    "    data = []\n",
    "    with open(path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            data.append(line.strip())\n",
    "    return data\n",
    "\n",
    "vi_data = read_data(vi_path)\n",
    "en_data = read_data(en_path)\n",
    "print(vi_data[:10])\n",
    "print(text_to_tensor(\"i love you!\", lang=\"en\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb569639",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T05:11:34.135972Z",
     "iopub.status.busy": "2024-05-03T05:11:34.135645Z",
     "iopub.status.idle": "2024-05-03T05:12:15.875818Z",
     "shell.execute_reply": "2024-05-03T05:12:15.874824Z"
    },
    "papermill": {
     "duration": 41.758783,
     "end_time": "2024-05-03T05:12:15.885709",
     "exception": false,
     "start_time": "2024-05-03T05:11:34.126926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([254090, 64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,  2,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 1, 14, 15, 16, 17,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 1, 18, 19,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 1, 20, 21, 22,  8, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32,  2,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 1, 33, 34, 35, 36, 37, 38, 39, 40, 41,  2,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 1, 42, 43, 34, 44, 45, 46,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 1, 47, 48, 49, 50, 19, 51, 52, 53, 34, 54,  2,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 1, 55, 56, 30, 34, 57, 58, 55, 59, 60, 61, 62, 63, 64, 65,  2,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 1, 66, 67, 68, 69, 11, 70, 71, 68,  2,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 1, 31, 72, 44, 73,  8, 74, 75, 76, 77,  2,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def data_to_tensor(data, lang):\n",
    "  tensor_data = []\n",
    "  for i in range(len(data)):\n",
    "    tensor_sent = text_to_tensor(sentence=data[i], lang=lang).unsqueeze(0)\n",
    "    tensor_data.append(tensor_sent)\n",
    "\n",
    "  tensor_data = torch.cat(tensor_data, dim=0)\n",
    "  return tensor_data\n",
    "\n",
    "vi_data_tensor = data_to_tensor(vi_data, lang=\"vi\")\n",
    "en_data_tensor = data_to_tensor(en_data, lang=\"en\")\n",
    "print(vi_data_tensor.shape)\n",
    "vi_data_tensor[:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee4a9d6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T05:12:15.903665Z",
     "iopub.status.busy": "2024-05-03T05:12:15.903023Z",
     "iopub.status.idle": "2024-05-03T05:12:15.908529Z",
     "shell.execute_reply": "2024-05-03T05:12:15.907499Z"
    },
    "papermill": {
     "duration": 0.016974,
     "end_time": "2024-05-03T05:12:15.910758",
     "exception": false,
     "start_time": "2024-05-03T05:12:15.893784",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7907\n",
      "22199\n"
     ]
    }
   ],
   "source": [
    "print(len(num_word_vi))\n",
    "print(len(num_word_en))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7649f9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T05:12:15.930501Z",
     "iopub.status.busy": "2024-05-03T05:12:15.929548Z",
     "iopub.status.idle": "2024-05-03T05:12:15.936377Z",
     "shell.execute_reply": "2024-05-03T05:12:15.935297Z"
    },
    "papermill": {
     "duration": 0.019278,
     "end_time": "2024-05-03T05:12:15.938723",
     "exception": false,
     "start_time": "2024-05-03T05:12:15.919445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "  def __init__(self, data_vi_tensor, data_en_tensor):\n",
    "    self.data_vi = data_vi_tensor \n",
    "    self.data_en = data_en_tensor\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.data_vi.shape[0]\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    return {\n",
    "        \"input_vi\": self.data_vi[index],\n",
    "        \"input_en\": self.data_en[index]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2fe71c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T05:12:15.958299Z",
     "iopub.status.busy": "2024-05-03T05:12:15.957395Z",
     "iopub.status.idle": "2024-05-03T05:12:16.211657Z",
     "shell.execute_reply": "2024-05-03T05:12:16.210486Z"
    },
    "papermill": {
     "duration": 0.26663,
     "end_time": "2024-05-03T05:12:16.214133",
     "exception": false,
     "start_time": "2024-05-03T05:12:15.947503",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   1,  148,   55,  236,  244,  579,  166,  276, 1069, 1070,  342,  183,\n",
      "         184,   44,  149,    2,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0]) tensor([   1,  149,   43,  151,   59,    6,  689,   30, 1585, 1290,  156,  510,\n",
      "          22,  134,    2,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0])\n"
     ]
    }
   ],
   "source": [
    "train_vi, test_vi, train_en, test_en = train_test_split(vi_data_tensor, en_data_tensor, test_size=0.2, random_state=42)\n",
    "train_vi, valid_vi, train_en, valid_en = train_test_split(train_vi, train_en, test_size=0.1, random_state=42)\n",
    "print(train_vi[0], train_en[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11865671",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T05:12:16.232639Z",
     "iopub.status.busy": "2024-05-03T05:12:16.232258Z",
     "iopub.status.idle": "2024-05-03T05:12:16.237580Z",
     "shell.execute_reply": "2024-05-03T05:12:16.236631Z"
    },
    "papermill": {
     "duration": 0.017027,
     "end_time": "2024-05-03T05:12:16.239709",
     "exception": false,
     "start_time": "2024-05-03T05:12:16.222682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(data_vi_tensor=train_vi, data_en_tensor=train_en)\n",
    "valid_dataset = CustomDataset(data_vi_tensor=valid_vi, data_en_tensor=valid_en)\n",
    "test_dataset = CustomDataset(data_vi_tensor=test_vi, data_en_tensor=test_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d255517",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T05:12:16.258043Z",
     "iopub.status.busy": "2024-05-03T05:12:16.257665Z",
     "iopub.status.idle": "2024-05-03T05:12:16.263431Z",
     "shell.execute_reply": "2024-05-03T05:12:16.262449Z"
    },
    "papermill": {
     "duration": 0.017557,
     "end_time": "2024-05-03T05:12:16.265623",
     "exception": false,
     "start_time": "2024-05-03T05:12:16.248066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3ee26a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T05:12:16.284501Z",
     "iopub.status.busy": "2024-05-03T05:12:16.283772Z",
     "iopub.status.idle": "2024-05-03T05:12:16.293183Z",
     "shell.execute_reply": "2024-05-03T05:12:16.292231Z"
    },
    "papermill": {
     "duration": 0.021173,
     "end_time": "2024-05-03T05:12:16.295435",
     "exception": false,
     "start_time": "2024-05-03T05:12:16.274262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, epochs, optimizer, criterion, train_loader: DataLoader, device):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        loss = None\n",
    "        for i, data in enumerate(train_loader): \n",
    "            input_vi = data['input_vi'].to(device)\n",
    "            input_en = data['input_en'].to(device)\n",
    "            output = model(input_vi, input_en) #batch_size, seq_len, trg_vocab_size\n",
    "            batch_size, seq_len, trg_vocab = output.shape\n",
    "\n",
    "            input_target = torch.zeros(batch_size, seq_len, trg_vocab).to(device)\n",
    "\n",
    "            for batch in range(batch_size):\n",
    "                for len in range(seq_len): \n",
    "                    a = torch.zeros(trg_vocab).to(device)\n",
    "                    a[input_en[batch, len]] = 1.\n",
    "                    input_target[batch, len] = a \n",
    "\n",
    "            loss = criterion(output, input_target)  \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "\n",
    "            if i % 128 == 0: \n",
    "                path = '/kaggle/working/model.pth'\n",
    "                torch.save(model.state_dict(), path)\n",
    "                print(f\"Epoch: {epoch}, step: {i}, train loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "679ffc80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T05:12:16.314476Z",
     "iopub.status.busy": "2024-05-03T05:12:16.313611Z",
     "iopub.status.idle": "2024-05-03T10:36:56.235549Z",
     "shell.execute_reply": "2024-05-03T10:36:56.234690Z"
    },
    "papermill": {
     "duration": 19479.934153,
     "end_time": "2024-05-03T10:36:56.238019",
     "exception": false,
     "start_time": "2024-05-03T05:12:16.303866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, step: 0, train loss: 0.0004943166277371347\n",
      "Epoch: 0, step: 128, train loss: 0.00010715109965531155\n",
      "Epoch: 0, step: 256, train loss: 7.530010043410584e-05\n",
      "Epoch: 0, step: 384, train loss: 5.970893471385352e-05\n",
      "Epoch: 0, step: 512, train loss: 4.8616930143907666e-05\n",
      "Epoch: 0, step: 640, train loss: 4.234011430526152e-05\n",
      "Epoch: 0, step: 768, train loss: 4.003898720839061e-05\n",
      "Epoch: 0, step: 896, train loss: 3.948991434299387e-05\n",
      "Epoch: 0, step: 1024, train loss: 3.881322481902316e-05\n",
      "Epoch: 0, step: 1152, train loss: 3.9614984416402876e-05\n",
      "Epoch: 0, step: 1280, train loss: 3.934179767384194e-05\n",
      "Epoch: 0, step: 1408, train loss: 3.7908455851720646e-05\n",
      "Epoch: 1, step: 0, train loss: 3.804587322520092e-05\n",
      "Epoch: 1, step: 128, train loss: 3.5336855944478884e-05\n",
      "Epoch: 1, step: 256, train loss: 3.441991066210903e-05\n",
      "Epoch: 1, step: 384, train loss: 3.5026907426072285e-05\n",
      "Epoch: 1, step: 512, train loss: 3.453363024163991e-05\n",
      "Epoch: 1, step: 640, train loss: 3.4288299502804875e-05\n",
      "Epoch: 1, step: 768, train loss: 3.465375993982889e-05\n",
      "Epoch: 1, step: 896, train loss: 3.576351446099579e-05\n",
      "Epoch: 1, step: 1024, train loss: 3.003553683811333e-05\n",
      "Epoch: 1, step: 1152, train loss: 3.0086208425927907e-05\n",
      "Epoch: 1, step: 1280, train loss: 3.3008451282512397e-05\n",
      "Epoch: 1, step: 1408, train loss: 3.090477912337519e-05\n",
      "Epoch: 2, step: 0, train loss: 3.258578362874687e-05\n",
      "Epoch: 2, step: 128, train loss: 2.790419057419058e-05\n",
      "Epoch: 2, step: 256, train loss: 3.070496313739568e-05\n",
      "Epoch: 2, step: 384, train loss: 3.065242344746366e-05\n",
      "Epoch: 2, step: 512, train loss: 2.861984285118524e-05\n",
      "Epoch: 2, step: 640, train loss: 2.5878027372527868e-05\n",
      "Epoch: 2, step: 768, train loss: 2.823773138516117e-05\n",
      "Epoch: 2, step: 896, train loss: 2.8893049602629617e-05\n",
      "Epoch: 2, step: 1024, train loss: 2.87304228550056e-05\n",
      "Epoch: 2, step: 1152, train loss: 2.6607200197759084e-05\n",
      "Epoch: 2, step: 1280, train loss: 3.004494465130847e-05\n",
      "Epoch: 2, step: 1408, train loss: 2.6876017727772705e-05\n",
      "Epoch: 3, step: 0, train loss: 2.8005792046315037e-05\n",
      "Epoch: 3, step: 128, train loss: 2.5479990654275753e-05\n",
      "Epoch: 3, step: 256, train loss: 2.3720214812783524e-05\n",
      "Epoch: 3, step: 384, train loss: 2.6730513127404265e-05\n",
      "Epoch: 3, step: 512, train loss: 2.5960145649150945e-05\n",
      "Epoch: 3, step: 640, train loss: 2.539073466323316e-05\n",
      "Epoch: 3, step: 768, train loss: 2.6655072360881604e-05\n",
      "Epoch: 3, step: 896, train loss: 2.6560990590951405e-05\n",
      "Epoch: 3, step: 1024, train loss: 2.6887510102824308e-05\n",
      "Epoch: 3, step: 1152, train loss: 2.5020573957590386e-05\n",
      "Epoch: 3, step: 1280, train loss: 2.452218541293405e-05\n",
      "Epoch: 3, step: 1408, train loss: 2.424047124804929e-05\n",
      "Epoch: 4, step: 0, train loss: 2.3904844056232832e-05\n",
      "Epoch: 4, step: 128, train loss: 2.3130896806833334e-05\n",
      "Epoch: 4, step: 256, train loss: 2.3657772544538602e-05\n",
      "Epoch: 4, step: 384, train loss: 2.2993939637672156e-05\n",
      "Epoch: 4, step: 512, train loss: 2.5304127120762132e-05\n",
      "Epoch: 4, step: 640, train loss: 2.2628228180110455e-05\n",
      "Epoch: 4, step: 768, train loss: 2.2998940039542504e-05\n",
      "Epoch: 4, step: 896, train loss: 2.4297391064465046e-05\n",
      "Epoch: 4, step: 1024, train loss: 2.3348989998339675e-05\n",
      "Epoch: 4, step: 1152, train loss: 2.270118784508668e-05\n",
      "Epoch: 4, step: 1280, train loss: 2.4411090635112487e-05\n",
      "Epoch: 4, step: 1408, train loss: 2.25641797442222e-05\n",
      "Epoch: 5, step: 0, train loss: 2.238660272269044e-05\n",
      "Epoch: 5, step: 128, train loss: 2.1951836970401928e-05\n",
      "Epoch: 5, step: 256, train loss: 2.1335001292754896e-05\n",
      "Epoch: 5, step: 384, train loss: 2.1373547497205436e-05\n",
      "Epoch: 5, step: 512, train loss: 2.1063551685074344e-05\n",
      "Epoch: 5, step: 640, train loss: 2.2291318600764498e-05\n",
      "Epoch: 5, step: 768, train loss: 2.1838690372533165e-05\n",
      "Epoch: 5, step: 896, train loss: 1.988971052924171e-05\n",
      "Epoch: 5, step: 1024, train loss: 2.1102627215441316e-05\n",
      "Epoch: 5, step: 1152, train loss: 2.1039077182649635e-05\n",
      "Epoch: 5, step: 1280, train loss: 2.081466664094478e-05\n",
      "Epoch: 5, step: 1408, train loss: 2.089436566166114e-05\n",
      "Epoch: 6, step: 0, train loss: 2.0942923583788797e-05\n",
      "Epoch: 6, step: 128, train loss: 1.8082906535710208e-05\n",
      "Epoch: 6, step: 256, train loss: 1.9883053028024733e-05\n",
      "Epoch: 6, step: 384, train loss: 2.0104404029552825e-05\n",
      "Epoch: 6, step: 512, train loss: 2.1150723114260472e-05\n",
      "Epoch: 6, step: 640, train loss: 1.9564949980122037e-05\n",
      "Epoch: 6, step: 768, train loss: 1.9789345969911665e-05\n",
      "Epoch: 6, step: 896, train loss: 1.9816759959212504e-05\n",
      "Epoch: 6, step: 1024, train loss: 1.8981023458763957e-05\n",
      "Epoch: 6, step: 1152, train loss: 2.1131072571733966e-05\n",
      "Epoch: 6, step: 1280, train loss: 1.843372047005687e-05\n",
      "Epoch: 6, step: 1408, train loss: 1.825936669774819e-05\n",
      "Epoch: 7, step: 0, train loss: 1.9812334357993677e-05\n",
      "Epoch: 7, step: 128, train loss: 1.8818018361344002e-05\n",
      "Epoch: 7, step: 256, train loss: 1.7326023225905374e-05\n",
      "Epoch: 7, step: 384, train loss: 1.7424261386622675e-05\n",
      "Epoch: 7, step: 512, train loss: 1.7656868294579908e-05\n",
      "Epoch: 7, step: 640, train loss: 1.773262738424819e-05\n",
      "Epoch: 7, step: 768, train loss: 1.833739224821329e-05\n",
      "Epoch: 7, step: 896, train loss: 1.7873870092444122e-05\n",
      "Epoch: 7, step: 1024, train loss: 1.795285425032489e-05\n",
      "Epoch: 7, step: 1152, train loss: 1.7006632333504967e-05\n",
      "Epoch: 7, step: 1280, train loss: 1.8440150597598404e-05\n",
      "Epoch: 7, step: 1408, train loss: 1.639316906221211e-05\n",
      "Epoch: 8, step: 0, train loss: 1.8427050235914066e-05\n",
      "Epoch: 8, step: 128, train loss: 1.7161881260108203e-05\n",
      "Epoch: 8, step: 256, train loss: 1.7898946680361405e-05\n",
      "Epoch: 8, step: 384, train loss: 1.7796362953959033e-05\n",
      "Epoch: 8, step: 512, train loss: 1.5906996850389987e-05\n",
      "Epoch: 8, step: 640, train loss: 1.652133505558595e-05\n",
      "Epoch: 8, step: 768, train loss: 1.577594412083272e-05\n",
      "Epoch: 8, step: 896, train loss: 1.8351474864175543e-05\n",
      "Epoch: 8, step: 1024, train loss: 1.6953905287664384e-05\n",
      "Epoch: 8, step: 1152, train loss: 1.635305306990631e-05\n",
      "Epoch: 8, step: 1280, train loss: 1.592808257555589e-05\n",
      "Epoch: 8, step: 1408, train loss: 1.9032684576814063e-05\n",
      "Epoch: 9, step: 0, train loss: 1.6215739378822036e-05\n",
      "Epoch: 9, step: 128, train loss: 1.6110529031720944e-05\n",
      "Epoch: 9, step: 256, train loss: 1.6071460777311586e-05\n",
      "Epoch: 9, step: 384, train loss: 1.481285198678961e-05\n",
      "Epoch: 9, step: 512, train loss: 1.5235670616675634e-05\n",
      "Epoch: 9, step: 640, train loss: 1.5023309970274568e-05\n",
      "Epoch: 9, step: 768, train loss: 1.5413195797009394e-05\n",
      "Epoch: 9, step: 896, train loss: 1.688576776359696e-05\n",
      "Epoch: 9, step: 1024, train loss: 1.4693136108689941e-05\n",
      "Epoch: 9, step: 1152, train loss: 1.597249683982227e-05\n",
      "Epoch: 9, step: 1280, train loss: 1.4953743630030658e-05\n",
      "Epoch: 9, step: 1408, train loss: 1.546741259517148e-05\n"
     ]
    }
   ],
   "source": [
    "SEQ_LEN = 64 \n",
    "D_MODEL = 128 \n",
    "SRC_VOCAB = len(num_word_vi)\n",
    "TRG_VOCAB = len(num_word_en)\n",
    "EPOCHS = 10\n",
    "LR = 2e-4\n",
    "NUM_LAYERS = 2\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "model = Transformer(d_model=D_MODEL, src_vocab_size=SRC_VOCAB, target_vocab_size=TRG_VOCAB, seq_len=SEQ_LEN, num_layer=NUM_LAYERS).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "train(model=model, epochs=EPOCHS, optimizer=optimizer, criterion=criterion, train_loader=train_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8e1420",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-02T22:58:06.234628Z",
     "iopub.status.idle": "2024-05-02T22:58:06.235067Z",
     "shell.execute_reply": "2024-05-02T22:58:06.234882Z",
     "shell.execute_reply.started": "2024-05-02T22:58:06.234859Z"
    },
    "papermill": {
     "duration": 0.016831,
     "end_time": "2024-05-03T10:36:56.273220",
     "exception": false,
     "start_time": "2024-05-03T10:36:56.256389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded61a6b",
   "metadata": {
    "papermill": {
     "duration": 0.016316,
     "end_time": "2024-05-03T10:36:56.305971",
     "exception": false,
     "start_time": "2024-05-03T10:36:56.289655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4926312,
     "sourceId": 8292556,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 19533.15895,
   "end_time": "2024-05-03T10:36:58.591852",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-03T05:11:25.432902",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
